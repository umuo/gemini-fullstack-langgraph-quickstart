# DeepResearcher - AIé©±åŠ¨çš„æ™ºèƒ½è¯•å·ç”Ÿæˆç³»ç»Ÿ

ğŸ¯ **åŸºäºLangGraphçš„å…¨æ ˆAIç ”ç©¶å’Œè¯•å·ç”Ÿæˆç³»ç»Ÿ**

è¿™æ˜¯ä¸€ä¸ªé›†æˆäº†æ·±åº¦ç ”ç©¶ã€æ™ºèƒ½è¯•å·ç”Ÿæˆã€å­¦ä¹ ç¬”è®°åˆ¶ä½œç­‰åŠŸèƒ½çš„å…¨æ ˆåº”ç”¨ã€‚ç³»ç»Ÿä½¿ç”¨Reactå‰ç«¯å’ŒLangGraphåç«¯ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šè½®æ™ºèƒ½ç ”ç©¶ï¼ŒåŠ¨æ€ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼Œå¹¶åŸºäºç ”ç©¶ç»“æœç”Ÿæˆä¸“ä¸šçš„è¯•å·å’Œå­¦ä¹ ææ–™ã€‚

> **Note**: This project has been migrated from Google Genai to support OpenAI compatible APIs. See [OPENAI_MIGRATION.md](backend/OPENAI_MIGRATION.md) for migration details.

<img src="./app.png" title="Gemini Fullstack LangGraph" alt="Gemini Fullstack LangGraph" width="90%">

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

### ğŸ”¬ AIæ·±åº¦ç ”ç©¶åŠ©æ‰‹
- ğŸ’¬ Reactå‰ç«¯ + LangGraphåç«¯çš„å…¨æ ˆæ¶æ„
- ğŸ§  åŸºäºLangGraphçš„é«˜çº§ç ”ç©¶å’Œå¯¹è¯AI
- ğŸ” ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å‹åŠ¨æ€ç”Ÿæˆæœç´¢æŸ¥è¯¢
- ğŸŒ é›†æˆç ”ç©¶èƒ½åŠ›ï¼ˆå¯æ‰©å±•æœç´¢APIï¼‰
- ğŸ¤” åæ€æ¨ç†è¯†åˆ«çŸ¥è¯†ç©ºç™½å¹¶ä¼˜åŒ–æœç´¢
- ğŸ“„ ç”Ÿæˆå¸¦å¼•ç”¨æ¥æºçš„ç­”æ¡ˆ

### ğŸ“ æ™ºèƒ½è¯•å·ç”Ÿæˆç³»ç»Ÿ
- ğŸ¯ **å¤šé¢˜å‹æ”¯æŒ**ï¼šé€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ã€å¡«ç©ºé¢˜ã€ç®€ç­”é¢˜ã€è®ºè¿°é¢˜ã€è®¡ç®—é¢˜ã€åˆ†æé¢˜ã€åº”ç”¨é¢˜
- ğŸ“Š **éš¾åº¦åˆ†çº§**ï¼šç®€å•ã€ä¸­ç­‰ã€å›°éš¾ä¸‰ä¸ªç­‰çº§
- ğŸ« **å­¦æ®µé€‚é…**ï¼šå°å­¦ã€åˆä¸­ã€é«˜ä¸­å…¨è¦†ç›–
- ğŸ“š **å­¦ç§‘é½å…¨**ï¼šæ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ã€ç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ç­‰
- ğŸ“„ **ä¸“ä¸šPDF**ï¼šåŒæ å¸ƒå±€ã€LaTeXæ•°å­¦å…¬å¼ã€ä¸­æ–‡å­—ä½“æ”¯æŒ
- ğŸ§¹ **æ¸…æ´æ ¼å¼**ï¼šç®€åŒ–å¤´éƒ¨ã€æ ‡å‡†åŒ–é€‰é¡¹ã€ä¸“ä¸šå¤–è§‚
- ğŸ“‹ **å¤šç‰ˆæœ¬è¾“å‡º**ï¼šè¯•å·ã€ç­”æ¡ˆã€å­¦ä¹ ç¬”è®°ä¸‰åˆä¸€

### ğŸ“š å­¦ä¹ ç¬”è®°ç”Ÿæˆ
- ğŸ“– **ç»“æ„åŒ–å†…å®¹**ï¼šä¸»é¢˜æ¦‚è¿°ã€æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€å­¦ä¹ æŠ€å·§ã€æ‰©å±•çŸ¥è¯†
- ğŸ¯ **æ™ºèƒ½åˆ†ç±»**ï¼šé‡è¦ç¨‹åº¦æ ‡æ³¨ï¼ˆğŸ”µåŸºç¡€/ğŸŸ¡é‡è¦/ğŸ”´æ ¸å¿ƒï¼‰
- ğŸ’¡ **æŠ€å·§æŒ‡å¯¼**ï¼šğŸ§ è®°å¿†/ğŸ’¡ç†è§£/âš¡åº”ç”¨/ğŸ¯è§£é¢˜å››å¤§ç±»åˆ«
- ğŸŒŸ **æ‰©å±•å­¦ä¹ **ï¼šç›¸å…³çŸ¥è¯†ç‚¹å…³è”å’Œæ‹“å±•å†…å®¹

## Project Structure

The project is divided into two main directories:

-   `frontend/`: Contains the React application built with Vite.
-   `backend/`: Contains the LangGraph/FastAPI application, including the research agent logic.

## Getting Started: Development and Local Testing

Follow these steps to get the application running locally for development and testing.

**1. Prerequisites:**

-   Node.js and npm (or yarn/pnpm)
-   Python 3.11+
-   **OpenAI Compatible API**: The backend agent requires an OpenAI compatible API configuration.
    1.  Navigate to the `backend/` directory.
    2.  Create a file named `.env` by copying the `backend/.env.example` file.
    3.  Open the `.env` file and configure your API settings:
        ```bash
        OPENAI_API_KEY=your_api_key_here
        OPENAI_BASE_URL=https://api.openai.com/v1  # or your custom endpoint
        OPENAI_MODEL=gpt-4o  # or your preferred model
        ```

**2. Install Dependencies:**

**Backend:**

```bash
cd backend
pip install .
```

**Frontend:**

```bash
cd frontend
npm install
```

**3. Test Configuration (Optional):**

Test your OpenAI compatible API configuration:

```bash
cd backend
python test_openai_config.py
```

**4. Run Development Servers:**

**å¿«é€Ÿå¯åŠ¨ (æ¨è):**

```bash
./start_dev.sh
```

è¿™å°†å¯åŠ¨åç«¯å’Œå‰ç«¯å¼€å‘æœåŠ¡å™¨ã€‚è®¿é—® `http://localhost:5173` ä½¿ç”¨åº”ç”¨ã€‚

**åœæ­¢æœåŠ¡:**

```bash
./stop_dev.sh
```

**æ‰‹åŠ¨å¯åŠ¨ (å¯é€‰):**

```bash
make dev
```

_æˆ–è€…åˆ†åˆ«å¯åŠ¨æœåŠ¡ï¼šåç«¯åœ¨ `backend/` ç›®å½•è¿è¡Œ `langgraph dev`ï¼Œå‰ç«¯åœ¨ `frontend/` ç›®å½•è¿è¡Œ `npm run dev`ã€‚_

**åŠŸèƒ½è®¿é—®:**
- ğŸ”¬ ç ”ç©¶åŠ©æ‰‹: `http://localhost:5173/` 
- ğŸ“ è¯•å·ç”Ÿæˆå™¨: `http://localhost:5173/exam`

## ğŸ¯ è¯•å·ç”Ÿæˆæ¼”ç¤º

### å¿«é€Ÿç”Ÿæˆç¤ºä¾‹
```
è¾“å…¥å‚æ•°ï¼š
- å­¦ç§‘ï¼šæ•°å­¦
- å­¦æ®µï¼šåˆä¸­  
- ä¸»é¢˜ï¼šäºŒæ¬¡å‡½æ•°
- é¢˜å‹ï¼šé€‰æ‹©é¢˜ + è®¡ç®—é¢˜
- éš¾åº¦ï¼šä¸­ç­‰
- æ•°é‡ï¼š15é¢˜

è¾“å‡ºç»“æœï¼š
âœ… ä¸“ä¸šæ ¼å¼PDFè¯•å·
âœ… è¯¦ç»†è§£ç­”PDF
âœ… å­¦ä¹ ç¬”è®°PDF
```

### æ ¼å¼ç‰¹æ€§å±•ç¤º
```
ä¿®å¤å‰ï¼š
1. 0.6 + 0.4 = ? (2åˆ†)
A. A) 1.0    â† é‡å¤æ ‡å·é—®é¢˜
B. B) 0.10
C. C) 0.2

ä¿®å¤åï¼š
1. 0.6 + 0.4 = ? (2åˆ†)  
A. 1.0       â† æ¸…æ´æ ‡å‡†æ ¼å¼
B. 0.10
C. 0.2
```

## ğŸ§ª åŠŸèƒ½æµ‹è¯•

```bash
cd backend

# å®Œæ•´åŠŸèƒ½æµ‹è¯•
python test_complete_generation.py

# æ¸…æ´æ ¼å¼æµ‹è¯•  
python test_clean_format.py

# æ•°å­¦å…¬å¼æµ‹è¯•
python test_latex_math.py

# åŒæ å¸ƒå±€æµ‹è¯•
python test_two_column_layout.py

# ä¸­æ–‡å­—ä½“æµ‹è¯•
python test_font_simple.py
```

## How the Backend Agent Works (High-Level)

The core of the backend is a LangGraph agent defined in `backend/src/agent/graph.py`. It follows these steps:

<img src="./agent.png" title="Agent Flow" alt="Agent Flow" width="50%">

1.  **Generate Initial Queries:** Based on your input, it generates a set of initial search queries using an OpenAI compatible model.
2.  **Research:** For each query, it uses the configured model to generate research content (extensible with search APIs).
3.  **Reflection & Knowledge Gap Analysis:** The agent analyzes the research results to determine if the information is sufficient or if there are knowledge gaps.
4.  **Iterative Refinement:** If gaps are found or the information is insufficient, it generates follow-up queries and repeats the research and reflection steps (up to a configured maximum number of loops).
5.  **Finalize Answer:** Once the research is deemed sufficient, the agent synthesizes the gathered information into a coherent answer with citations.

## CLI Example

For quick one-off questions you can execute the agent from the command line. The
script `backend/examples/cli_research.py` runs the LangGraph agent and prints the
final answer:

```bash
cd backend
python examples/cli_research.py "What are the latest trends in renewable energy?"
```


## Deployment

In production, the backend server serves the optimized static frontend build. LangGraph requires a Redis instance and a Postgres database. Redis is used as a pub-sub broker to enable streaming real time output from background runs. Postgres is used to store assistants, threads, runs, persist thread state and long term memory, and to manage the state of the background task queue with 'exactly once' semantics. For more details on how to deploy the backend server, take a look at the [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/deployment_options/). Below is an example of how to build a Docker image that includes the optimized frontend build and the backend server and run it via `docker-compose`.

_Note: For the docker-compose.yml example you need a LangSmith API key, you can get one from [LangSmith](https://smith.langchain.com/settings)._

_Note: If you are not running the docker-compose.yml example or exposing the backend server to the public internet, you should update the `apiUrl` in the `frontend/src/App.tsx` file to your host. Currently the `apiUrl` is set to `http://localhost:8123` for docker-compose or `http://localhost:2024` for development._

**1. Build the Docker Image:**

   Run the following command from the **project root directory**:
   ```bash
   docker build -t openai-fullstack-langgraph -f Dockerfile .
   ```
**2. Run the Production Server:**

   ```bash
   OPENAI_API_KEY=<your_openai_api_key> OPENAI_BASE_URL=<your_base_url> OPENAI_MODEL=<your_model> LANGSMITH_API_KEY=<your_langsmith_api_key> docker-compose up
   ```

Open your browser and navigate to `http://localhost:8123/app/` to see the application. The API will be available at `http://localhost:8123`.

## ğŸ“š å®Œæ•´æ–‡æ¡£

- ğŸ“– **[é¡¹ç›®å®Œæ•´ä»‹ç»](PROJECT_OVERVIEW.md)** - è¯¦ç»†çš„åŠŸèƒ½ç‰¹æ€§ã€æŠ€æœ¯æ¶æ„ã€éƒ¨ç½²æŒ‡å—
- ğŸš€ **[å¿«é€Ÿå…¥é—¨æŒ‡å—](QUICK_START_GUIDE.md)** - 5åˆ†é’Ÿä¸Šæ‰‹ï¼ŒåŠŸèƒ½ä½“éªŒï¼Œé—®é¢˜è§£å†³
- ğŸ†š **[åŠŸèƒ½ç‰¹æ€§å¯¹æ¯”](FEATURES_COMPARISON.md)** - ä¸ä¼ ç»Ÿæ–¹æ³•çš„å…¨é¢å¯¹æ¯”åˆ†æ
- ğŸ§¹ **[æ¸…æ´æ ¼å¼æŒ‡å—](CLEAN_FORMAT_GUIDE.md)** - è¯•å·æ ¼å¼ä¼˜åŒ–å’Œé—®é¢˜ä¿®å¤
- ğŸ“ **[åŒæ å¸ƒå±€æŒ‡å—](TWO_COLUMN_LAYOUT_GUIDE.md)** - ä¸“ä¸šå¸ƒå±€è®¾è®¡è¯¦è§£
- ğŸ”¢ **[LaTeXæ•°å­¦æŒ‡å—](LATEX_MATH_GUIDE.md)** - æ•°å­¦å…¬å¼æ¸²æŸ“æ”¯æŒ
- ğŸ“ **[å­¦ä¹ ç¬”è®°æŒ‡å—](STUDY_NOTES_GUIDE.md)** - æ™ºèƒ½ç¬”è®°ç”ŸæˆåŠŸèƒ½

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### å‰ç«¯æŠ€æœ¯
- **[React](https://reactjs.org/)** + **[Vite](https://vitejs.dev/)** - ç°ä»£åŒ–å‰ç«¯æ¡†æ¶
- **[TypeScript](https://www.typescriptlang.org/)** - ç±»å‹å®‰å…¨çš„JavaScript
- **[Tailwind CSS](https://tailwindcss.com/)** - å®ç”¨ä¼˜å…ˆçš„CSSæ¡†æ¶
- **[Shadcn UI](https://ui.shadcn.com/)** - é«˜è´¨é‡ç»„ä»¶åº“

### åç«¯æŠ€æœ¯  
- **[LangGraph](https://github.com/langchain-ai/langgraph)** - AIå·¥ä½œæµç¼–æ’æ¡†æ¶
- **[FastAPI](https://fastapi.tiangolo.com/)** - é«˜æ€§èƒ½Python Webæ¡†æ¶
- **[ReportLab](https://www.reportlab.com/)** - ä¸“ä¸šPDFç”Ÿæˆåº“
- **[OpenAI API](https://platform.openai.com/docs/api-reference)** - GPT-4é©±åŠ¨çš„AIæœåŠ¡

### æ ¸å¿ƒç‰¹æ€§
- ğŸ¤– **AIé©±åŠ¨** - GPT-4æä¾›æ™ºèƒ½ç”Ÿæˆèƒ½åŠ›
- ğŸ“„ **ä¸“ä¸šPDF** - LaTeXæ•°å­¦å…¬å¼ + ä¸­æ–‡å­—ä½“æ”¯æŒ  
- ğŸ¨ **åŒæ å¸ƒå±€** - 40%ç©ºé—´åˆ©ç”¨ç‡æå‡
- ğŸ§¹ **æ¸…æ´æ ¼å¼** - è‡ªåŠ¨ä¿®å¤é€‰é¡¹æ ‡å·é—®é¢˜
- ğŸ” **æ·±åº¦ç ”ç©¶** - å¤šè½®åæ€ä¼˜åŒ–å†…å®¹è´¨é‡

## License

This project is licensed under the Apache License 2.0. See the [LICENSE](LICENSE) file for details. 
